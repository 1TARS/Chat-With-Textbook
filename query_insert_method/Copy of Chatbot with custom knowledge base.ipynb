{"cells":[{"cell_type":"markdown","metadata":{"id":"ZwaLK4kD1Uar"},"source":["#Introduction\n","\n","This notebook has all the code you need to create your own chatbot with custom knowledge base using GPT-3.\n","\n","Follow the instructions for each steps and then run the code sample. In order to run the code, you need to press \"play\" button near each code sample."]},{"cell_type":"markdown","metadata":{"id":"rD4Qzglp3J-h"},"source":["#Download the data for your custom knowledge base\n","For the demonstration purposes we are going to use ----- as our knowledge base. You can download them to your local folder from the github repository by running the code below.\n","Alternatively, you can put your own custom data into the local folder."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":599,"status":"ok","timestamp":1678306481166,"user":{"displayName":"Irina Nik","userId":"10422464625307671769"},"user_tz":-60},"id":"3cCyU-vV5Yb0","outputId":"3541b6ac-ae15-4ea7-8fc1-c710820d26a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'context_data'...\n"]},{"name":"stdout","output_type":"stream","text":["remote: Enumerating objects: 30, done.\u001b[K\n","remote: Counting objects: 100% (7/7), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 30 (delta 4), reused 4 (delta 4), pack-reused 23\u001b[K\n","Receiving objects: 100% (30/30), 12.58 KiB | 348.00 KiB/s, done.\n","Resolving deltas: 100% (13/13), done.\n"]}],"source":["! git clone https://github.com/irina1nik/context_data.git"]},{"cell_type":"markdown","metadata":{"id":"XiUyHP4T2g5F"},"source":["# Install the dependicies\n","Run the code below to install the depencies we need for our functions"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6LL4rxT6_W7h"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting llama-index==0.5.6\n","  Downloading llama_index-0.5.6.tar.gz (165 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting dataclasses_json\n","  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n","Collecting langchain\n","  Downloading langchain-0.0.351-py3-none-any.whl (794 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /home/tristan/.local/lib/python3.10/site-packages (from llama-index==0.5.6) (1.23.5)\n","Collecting tenacity<9.0.0,>=8.2.0\n","  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n","Requirement already satisfied: openai>=0.26.4 in /home/tristan/.local/lib/python3.10/site-packages (from llama-index==0.5.6) (0.28.1)\n","Requirement already satisfied: pandas in /home/tristan/.local/lib/python3.10/site-packages (from llama-index==0.5.6) (2.1.3)\n","Collecting tiktoken\n","  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /home/tristan/.local/lib/python3.10/site-packages (from openai>=0.26.4->llama-index==0.5.6) (3.8.6)\n","Requirement already satisfied: requests>=2.20 in /home/tristan/.local/lib/python3.10/site-packages (from openai>=0.26.4->llama-index==0.5.6) (2.31.0)\n","Requirement already satisfied: tqdm in /home/tristan/.local/lib/python3.10/site-packages (from openai>=0.26.4->llama-index==0.5.6) (4.66.1)\n","Collecting typing-inspect<1,>=0.4.0\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting marshmallow<4.0.0,>=3.18.0\n","  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic<3,>=1\n","  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-community<0.1,>=0.0.2\n","  Downloading langchain_community-0.0.4-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting SQLAlchemy<3,>=1.4\n","  Downloading SQLAlchemy-2.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting langsmith<0.1.0,>=0.0.70\n","  Downloading langsmith-0.0.72-py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jsonpatch<2.0,>=1.33\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-core<0.2,>=0.1\n","  Downloading langchain_core-0.1.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain->llama-index==0.5.6) (5.4.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/tristan/.local/lib/python3.10/site-packages (from langchain->llama-index==0.5.6) (4.0.3)\n","Requirement already satisfied: pytz>=2020.1 in /home/tristan/.local/lib/python3.10/site-packages (from pandas->llama-index==0.5.6) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/tristan/.local/lib/python3.10/site-packages (from pandas->llama-index==0.5.6) (2023.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/tristan/.local/lib/python3.10/site-packages (from pandas->llama-index==0.5.6) (2.8.2)\n","Collecting regex>=2022.1.18\n","  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 KB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->llama-index==0.5.6) (23.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->llama-index==0.5.6) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->llama-index==0.5.6) (6.0.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->llama-index==0.5.6) (1.4.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->llama-index==0.5.6) (1.9.2)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp->openai>=0.26.4->llama-index==0.5.6) (3.3.0)\n","Collecting jsonpointer>=1.9\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /home/tristan/.local/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain->llama-index==0.5.6) (23.2)\n","Collecting anyio<5,>=3\n","  Downloading anyio-4.2.0-py3-none-any.whl (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions>=4.6.1\n","  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n","Collecting pydantic-core==2.14.5\n","  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting annotated-types>=0.4.0\n","  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n","Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index==0.5.6) (1.16.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tristan/.local/lib/python3.10/site-packages (from requests>=2.20->openai>=0.26.4->llama-index==0.5.6) (2.0.6)\n","Requirement already satisfied: idna<4,>=2.5 in /home/tristan/.local/lib/python3.10/site-packages (from requests>=2.20->openai>=0.26.4->llama-index==0.5.6) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/tristan/.local/lib/python3.10/site-packages (from requests>=2.20->openai>=0.26.4->llama-index==0.5.6) (2023.7.22)\n","Collecting greenlet!=0.4.17\n","  Downloading greenlet-3.0.2-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.4/613.4 KB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mypy-extensions>=0.3.0\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /home/tristan/.local/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain->llama-index==0.5.6) (1.1.3)\n","Collecting sniffio>=1.1\n","  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n","Building wheels for collected packages: llama-index\n","  Building wheel for llama-index (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for llama-index: filename=llama_index-0.5.6-py3-none-any.whl size=248137 sha256=51596439a7e3d3fe828521139025afe491d1a5872ac43ccff1e6ad91fa001a4a\n","  Stored in directory: /home/tristan/.cache/pip/wheels/48/9f/0a/a5d7181a1819086f8288d1becdad81de07fc874b55075dde19\n","Successfully built llama-index\n","Installing collected packages: typing-extensions, tenacity, sniffio, regex, mypy-extensions, marshmallow, jsonpointer, greenlet, annotated-types, typing-inspect, tiktoken, SQLAlchemy, pydantic-core, jsonpatch, anyio, pydantic, dataclasses_json, langsmith, langchain-core, langchain-community, langchain, llama-index\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.4.0\n","    Uninstalling typing_extensions-4.4.0:\n","      Successfully uninstalled typing_extensions-4.4.0\n","Successfully installed SQLAlchemy-2.0.23 annotated-types-0.6.0 anyio-4.2.0 dataclasses_json-0.6.3 greenlet-3.0.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.351 langchain-community-0.0.4 langchain-core-0.1.1 langsmith-0.0.72 llama-index-0.5.6 marshmallow-3.20.1 mypy-extensions-1.0.0 pydantic-2.5.2 pydantic-core-2.14.5 regex-2023.10.3 sniffio-1.3.0 tenacity-8.2.3 tiktoken-0.5.2 typing-extensions-4.9.0 typing-inspect-0.9.0\n","Note: you may need to restart the kernel to use updated packages.\n","Defaulting to user installation because normal site-packages is not writeable\n","Collecting langchain==0.0.148\n","  Downloading langchain-0.0.148-py3-none-any.whl (636 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.7/636.7 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting numexpr<3.0.0,>=2.8.4\n","  Downloading numexpr-2.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (374 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 KB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/lib/python3/dist-packages (from langchain==0.0.148) (5.4.1)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/tristan/.local/lib/python3.10/site-packages (from langchain==0.0.148) (3.8.6)\n","Collecting SQLAlchemy<2,>=1\n","  Downloading SQLAlchemy-1.4.50-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting pydantic<2,>=1\n","  Downloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/tristan/.local/lib/python3.10/site-packages (from langchain==0.0.148) (4.0.3)\n","Requirement already satisfied: numpy<2,>=1 in /home/tristan/.local/lib/python3.10/site-packages (from langchain==0.0.148) (1.23.5)\n","Requirement already satisfied: requests<3,>=2 in /home/tristan/.local/lib/python3.10/site-packages (from langchain==0.0.148) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/tristan/.local/lib/python3.10/site-packages (from langchain==0.0.148) (8.2.3)\n","Collecting dataclasses-json<0.6.0,>=0.5.7\n","  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n","Requirement already satisfied: tqdm>=4.48.0 in /home/tristan/.local/lib/python3.10/site-packages (from langchain==0.0.148) (4.66.1)\n","Collecting openapi-schema-pydantic<2.0,>=1.2\n","  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (1.9.2)\n","Requirement already satisfied: attrs>=17.3.0 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/tristan/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (3.3.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/tristan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.148) (3.20.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/tristan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.148) (0.9.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /home/tristan/.local/lib/python3.10/site-packages (from pydantic<2,>=1->langchain==0.0.148) (4.9.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tristan/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.148) (2.0.6)\n","Requirement already satisfied: idna<4,>=2.5 in /home/tristan/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.148) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/tristan/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.148) (2023.7.22)\n","Requirement already satisfied: greenlet!=0.4.17 in /home/tristan/.local/lib/python3.10/site-packages (from SQLAlchemy<2,>=1->langchain==0.0.148) (3.0.2)\n","Requirement already satisfied: packaging>=17.0 in /home/tristan/.local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.148) (23.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /home/tristan/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.148) (1.0.0)\n","Installing collected packages: SQLAlchemy, pydantic, numexpr, openapi-schema-pydantic, dataclasses-json, langchain\n","  Attempting uninstall: SQLAlchemy\n","    Found existing installation: SQLAlchemy 2.0.23\n","    Uninstalling SQLAlchemy-2.0.23:\n","      Successfully uninstalled SQLAlchemy-2.0.23\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.5.2\n","    Uninstalling pydantic-2.5.2:\n","      Successfully uninstalled pydantic-2.5.2\n","  Attempting uninstall: dataclasses-json\n","    Found existing installation: dataclasses-json 0.6.3\n","    Uninstalling dataclasses-json-0.6.3:\n","      Successfully uninstalled dataclasses-json-0.6.3\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.0.351\n","    Uninstalling langchain-0.0.351:\n","      Successfully uninstalled langchain-0.0.351\n","Successfully installed SQLAlchemy-1.4.50 dataclasses-json-0.5.14 langchain-0.0.148 numexpr-2.8.8 openapi-schema-pydantic-1.2.4 pydantic-1.10.13\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install llama-index==0.5.6\n","%pip install langchain==0.0.148"]},{"cell_type":"markdown","metadata":{"id":"FbuYetOy25eM"},"source":["# Define the functions\n","The following code defines the functions we need to construct the index and query it"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"UelAqQgk_yIt"},"outputs":[],"source":["from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper, ServiceContext\n","from langchain import OpenAI\n","import sys\n","import os\n","from IPython.display import Markdown, display\n","\n","def construct_index(directory_path):\n","    # set maximum input size\n","    max_input_size = 4096\n","    # set number of output tokens\n","    num_outputs = 2000\n","    # set maximum chunk overlap\n","    max_chunk_overlap = 20\n","    # set chunk size limit\n","    chunk_size_limit = 600\n","\n","    # define prompt helper\n","    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n","\n","    # define LLM\n","    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.2, model_name=\"gpt-4-1106-preview\", max_tokens=num_outputs))\n","\n","    documents = SimpleDirectoryReader(directory_path).load_data()\n","\n","    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n","    index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)\n","\n","    index.save_to_disk('index.json')\n","\n","    return index\n","\n","def ask_ai():\n","    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n","    while True:\n","        query = input(\"What do you want to ask? \")\n","        response = index.query(query)\n","        display(Markdown(f\"Response: <b>{response.response}</b>\"))"]},{"cell_type":"markdown","metadata":{"id":"Vz1jp33jGumu"},"source":["# Set OpenAI API Key\n","You need an OPENAI API key to be able to run this code.\n","\n","If you don't have one yet, get it by [signing up](https://platform.openai.com/overview). Then click your account icon on the top right of the screen and select \"View API Keys\". Create an API key.\n","\n","Then run the code below and paste your API key into the text input."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"RoJHE4fsAT3w"},"outputs":[],"source":["os.environ[\"OPENAI_API_KEY\"] = input(\"Paste your OpenAI key here and hit enter:\")"]},{"cell_type":"markdown","metadata":{"id":"ZVrddlAL4I_v"},"source":["#Construct an index\n","Now we are ready to construct the index. This will take every file in the folder 'data', split it into chunks, and embed it with OpenAI's embeddings API.\n","\n","**Notice:** running this code will cost you credits on your OpenAPI account ($0.02 for every 1,000 tokens). If you've just set up your account, the free credits that you have should be more than enough for this experiment."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"kCYTE2EqBB7O"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/tristan/.local/lib/python3.10/site-packages/langchain/llms/openai.py:165: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n","  warnings.warn(\n","/home/tristan/.local/lib/python3.10/site-packages/langchain/llms/openai.py:672: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n","  warnings.warn(\n","INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n","INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 910815 tokens\n"]},{"data":{"text/plain":["<llama_index.indices.vector_store.vector_indices.GPTSimpleVectorIndex at 0x7fc4dfac96c0>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["construct_index(\"context_data/data\")"]},{"cell_type":"markdown","metadata":{"id":"ipJ_gYxN5cWh"},"source":["#Ask questions\n","It's time to have fun and test our AI. Run the function that queries GPT and type your question into the input.\n","\n","If you've used the provided example data for your custom knowledge base, here are a few questions that you can ask:\n","1. Why people cook at home? Make classification\n","2. Make classification about what frustrates people about cooking?\n","3. Brainstorm marketing campaign ideas for an air fryer that would appeal people that cook at home\n","4. Which kitchen appliences people use most often?\n","5. What people like about cooking at home?"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"background_save":true},"id":"s_uwsPGEIGsb"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4314 tokens\n","INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"]},{"data":{"text/markdown":["Response: <b>\n","\n","The Bellman-Ford algorithm is an algorithm for finding the shortest paths from a single source vertex to all other vertices in a weighted, directed graph. It works by iteratively relaxing the edges of the graph, and can detect negative-weight cycles. It runs in O(VE) time, where V is the number of vertices and E is the number of edges. It can be used to find the critical path in a PERT chart by either negating the edge weights and running DAG-SHORTEST-PATHS, or running DAG-SHORTEST-PATHS but replacing <1= by <1= in line 2 of INITIALIZE-SINGLE-SOURCE and <>= by <<= in the RELAX procedure.</b>"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4572 tokens\n","INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 12 tokens\n"]},{"data":{"text/markdown":["Response: <b>\n","\n","Divide and conquer algorithms are a type of algorithm that divide a problem into smaller subproblems, solve the subproblems, and then combine the solutions to the subproblems to solve the original problem. This technique dates back to at least 1202, when it was used by Leonardo Bonacci (also known as Fibonacci) to study Fibonacci numbers. It has since been used in many applications, such as matrix multiplication, chip testing, and Monge arrays.\n","\n","The divide and conquer technique can be used to solve recurrences, such as the Fibonacci recurrence, by using the method of generating functions. It can also be used to identify good chips in a set of supposedly identical integrated-circuit chips, by using a recursive algorithm that reduces the problem to one of nearly half the size. The master method and the Akra-Bazzi method are two general methods for solving recurrences arising from the analysis of divide-and-conquer algorithms.\n","\n","In general, divide and conquer algorithms can be used to solve problems more efficiently than other methods, as they break down the problem into smaller subproblems that can be solved more quickly.</b>"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4602 tokens\n","INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 12 tokens\n"]},{"data":{"text/markdown":["Response: <b>\n","\n","// Divide and Conquer Algorithm\n","\n","// Input: Array A of size n\n","\n","// Output: Result of the algorithm\n","\n","function divideAndConquer(A, n) {\n","  // Base case\n","  if (n == 1) {\n","    return A[0];\n","  }\n","  \n","  // Divide\n","  mid = n/2;\n","  left = A[0..mid-1];\n","  right = A[mid..n-1];\n","  \n","  // Conquer\n","  leftResult = divideAndConquer(left, mid);\n","  rightResult = divideAndConquer(right, n-mid);\n","  \n","  // Combine\n","  result = combine(leftResult, rightResult);\n","  \n","  return result;\n","}\n","\n","// Akra-Bazzi Method\n","\n","// Input: Array A of size n\n","\n","// Output: Result of the algorithm\n","\n","function akraBazzi(A, n) {\n","  // Base case\n","  if (n == 1) {\n","    return A[0];\n","  }\n","  \n","  // Divide\n","  mid = n/2;\n","  left = A[0..mid-</b>"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 4814 tokens\n","INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 12 tokens\n"]},{"data":{"text/markdown":["Response: <b>\n","\n","F LOYD -WARSHALL .W; n/\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","\n","let D .0/ D dij.0/ be a new n  n matrix\n","for i D 1 to n\n","for j D 1 to n\n","if i == j or wij D 1\n","dij.0/ D 0\n","else dij.0/ D \n","for k D 1 to n\n","let D .k/ D dij.k/ be a new n  n matrix\n","for i D 1 to n\n","for j D 1 to n\n","dij.k/ D min fdij.k1/ ; dik.k1/ C dkj.k1/ g\n","if dij.k/ < dij.k1/\n","�ij.k/ D k\n","for i D 1 to n\n","for j D 1 to n\n","if dij.n/ < \n","return D .n/\n","else return</b>"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:openai:error_code=None error_message=\"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n","INFO:openai:error_code=None error_message=\"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n","INFO:openai:error_code=None error_message=\"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n","INFO:openai:error_code=None error_message=\"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mask_ai\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[10], line 36\u001b[0m, in \u001b[0;36mask_ai\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat do you want to ask? \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     display(Markdown(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse: <b>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</b>\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/indices/base.py:244\u001b[0m, in \u001b[0;36mBaseGPTIndex.query\u001b[0;34m(self, query_str, mode, query_transform, use_async, **query_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m query_config \u001b[38;5;241m=\u001b[39m QueryConfig(\n\u001b[1;32m    231\u001b[0m     index_struct_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct\u001b[38;5;241m.\u001b[39mget_type(),\n\u001b[1;32m    232\u001b[0m     query_mode\u001b[38;5;241m=\u001b[39mmode_enum,\n\u001b[1;32m    233\u001b[0m     query_kwargs\u001b[38;5;241m=\u001b[39mquery_kwargs,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m query_runner \u001b[38;5;241m=\u001b[39m QueryRunner(\n\u001b[1;32m    236\u001b[0m     index_struct\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct,\n\u001b[1;32m    237\u001b[0m     service_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_context,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     use_async\u001b[38;5;241m=\u001b[39muse_async,\n\u001b[1;32m    243\u001b[0m )\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/indices/query/query_runner.py:342\u001b[0m, in \u001b[0;36mQueryRunner.query\u001b[0;34m(self, query_str_or_bundle, index_id, level)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run query.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03mNOTE: Relies on mutual recursion between\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    composable graph.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m query_combiner, query_bundle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_query_objects(\n\u001b[1;32m    340\u001b[0m     query_str_or_bundle, index_id\u001b[38;5;241m=\u001b[39mindex_id\n\u001b[1;32m    341\u001b[0m )\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_combiner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/indices/query/query_combiner/base.py:66\u001b[0m, in \u001b[0;36mSingleQueryCombiner.run\u001b[0;34m(self, query_bundle, level)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run query combiner.\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m updated_query_bundle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_update(query_bundle)\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_transformed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdated_query_bundle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/indices/query/query_runner.py:202\u001b[0m, in \u001b[0;36mQueryRunner.query_transformed\u001b[0;34m(self, query_bundle, index_struct, level)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/token_counter/token_counter.py:78\u001b[0m, in \u001b[0;36mllm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_llm_predict\u001b[39m(_self: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m wrapper_logic(_self):\n\u001b[0;32m---> 78\u001b[0m         f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f_return_val\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/indices/query/base.py:396\u001b[0m, in \u001b[0;36mBaseGPTIndexQuery.query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# TODO: support include summary\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/indices/query/base.py:382\u001b[0m, in \u001b[0;36mBaseGPTIndexQuery._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# TODO: remove _query and just use query\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthesize(query_bundle, nodes)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/indices/query/base.py:249\u001b[0m, in \u001b[0;36mBaseGPTIndexQuery.retrieve\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get list of tuples of node and similarity for response.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03mFirst part of the tuple is the node.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03mSecond part of tuple is the distance from query to the node.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03mIf not applicable, it's None.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m similarity_tracker \u001b[38;5;241m=\u001b[39m SimilarityTracker()\n\u001b[0;32m--> 249\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_tracker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimilarity_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m postprocess_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_tracker\u001b[39m\u001b[38;5;124m\"\u001b[39m: similarity_tracker,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_bundle\u001b[39m\u001b[38;5;124m\"\u001b[39m: query_bundle,\n\u001b[1;32m    254\u001b[0m }\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_preprocessors:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/indices/vector_store/base_query.py:53\u001b[0m, in \u001b[0;36mGPTVectorStoreIndexQuery._retrieve\u001b[0;34m(self, query_bundle, similarity_tracker)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mis_embedding_query:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_bundle\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         query_bundle\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 53\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_service_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_agg_embedding_from_queries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                \u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_strs\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m         )\n\u001b[1;32m     57\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mquery(\n\u001b[1;32m     58\u001b[0m         query_bundle\u001b[38;5;241m.\u001b[39membedding,\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_similarity_top_k,\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_doc_ids,\n\u001b[1;32m     61\u001b[0m     )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# TODO: fix function signature of query\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/embeddings/base.py:79\u001b[0m, in \u001b[0;36mBaseEmbedding.get_agg_embedding_from_queries\u001b[0;34m(self, queries, agg_fn)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_agg_embedding_from_queries\u001b[39m(\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     75\u001b[0m     queries: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m     76\u001b[0m     agg_fn: Optional[Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, List[\u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     77\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_query_embedding(query) \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries]\n\u001b[1;32m     80\u001b[0m     agg_fn \u001b[38;5;241m=\u001b[39m agg_fn \u001b[38;5;129;01mor\u001b[39;00m mean_agg\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agg_fn(query_embeddings)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/embeddings/base.py:79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_agg_embedding_from_queries\u001b[39m(\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     75\u001b[0m     queries: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m     76\u001b[0m     agg_fn: Optional[Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, List[\u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     77\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_query_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries]\n\u001b[1;32m     80\u001b[0m     agg_fn \u001b[38;5;241m=\u001b[39m agg_fn \u001b[38;5;129;01mor\u001b[39;00m mean_agg\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agg_fn(query_embeddings)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/embeddings/base.py:68\u001b[0m, in \u001b[0;36mBaseEmbedding.get_query_embedding\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_query_embedding\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get query embedding.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_query_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     query_tokens_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer(query))\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_tokens_used \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m query_tokens_count\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/embeddings/openai.py:223\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_query_embedding\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid mode, model combination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    222\u001b[0m     engine \u001b[38;5;241m=\u001b[39m _QUERY_MODE_MODEL_DICT[key]\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tenacity/__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[1;32m    388\u001b[0m     retry_state\u001b[38;5;241m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tenacity/nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["ask_ai()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1PQXcM_jhN6QJ7uTkxvNbxoI54r03uSr3","timestamp":1703028392951}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
